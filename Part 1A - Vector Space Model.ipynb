{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Assignment  \n",
    "## Part 1A: Vector Space Model\n",
    "\n",
    "---\n",
    "\n",
    "In this model, we will be representing each document as a vector of $\\left| V \\right|$ dimensions, where $ V $ is the vocabulary set, or the set of all terms present in the corpus. The document vectors have been stored together in a matrix, with the columns as the documents and the rows as the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shelve\n",
    "import pickle"
   ]
  },
  {
   "source": [
    "To view the memory usage by the program, tracemalloc module is used. The values of current and peak memory usage are printed at the end of the program."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = './wiki_93'\n",
    "# FILENAME = input('Please enter path to a wiki file: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Pass\n",
    "\n",
    "To represent the document as vectors, we first need a vocabulary set and a list/number of documents.\n",
    "That is why, in the first pass, we parse the given file to generate the following:\n",
    "- vocabulary set\n",
    "- a list of all documents in the file\n",
    "\n",
    "Each line in the document is:\n",
    "1. Converted to lower-case to remove case-sensitivity\n",
    "2. Matched with a regular expression to check if its a document opening tag <doc ...>\n",
    "    - If it is, then the document name is appended to the `docs` list\n",
    "3. If not, then all html anchor tags and punctuations are removed\n",
    "4. The line is split into words and the `vocab` set is updated with the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "docs = []\n",
    "\n",
    "with open(FILENAME) as file:\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        check = re.search('<doc id=\"(.*?)\" url=\"(.*?)\" title=\"(.*?)\">', line)\n",
    "        if check:\n",
    "            # 0 -> entire string, 1 -> id, 2 -> url, 3 -> title\n",
    "            docs.append(check[3])\n",
    "            continue\n",
    "\n",
    "        if line == '\\n' or line == '</doc>\\n':\n",
    "            continue\n",
    "\n",
    "        line = re.sub('<a.*?>|</a>', '', line)\n",
    "        line = re.sub('-|â€“|â€”', ' ', line)\n",
    "        line = line.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        vocab.update(set(line.strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the vocabulary is: 75614\nThe number of documents is: 5784\n"
     ]
    }
   ],
   "source": [
    "print('The size of the vocabulary is:', len(vocab))\n",
    "print('The number of documents is:', len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each term in the `vocab` set is given an ID and stored in a term -> term ID dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {word:index for index, word in enumerate(sorted(list(vocab)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass\n",
    "\n",
    "With the vocabulary set and document list generated, we can initialise and populate the document vectors.\n",
    "\n",
    "Here, the file is parsed again and for each term in each document, the relevent cell is updated with the term frequency of that term in that document.\n",
    "\n",
    "`document_vectors` is a table with rows as the terms and columns as the documents\n",
    "\n",
    "---\n",
    "Warning: This block takes  a couple of minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = pd.DataFrame(0, index=list(vocab_dict), columns=docs, dtype=np.byte)\n",
    "\n",
    "with open(FILENAME) as file:\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        check = re.search('<doc id=\"(.*?)\" url=\"(.*?)\" title=\"(.*?)\">', line)\n",
    "        if check:\n",
    "          # 0 -> entire string, 1 -> id, 2 -> url, 3 -> title\n",
    "          current_doc = check[3]\n",
    "          continue\n",
    "\n",
    "        if line == '\\n' or line == '</doc>\\n':  \n",
    "          continue\n",
    "\n",
    "        line = re.sub('<a.*?>|</a>', '', line)\n",
    "        line = re.sub('-|â€“|â€”', ' ', line)\n",
    "        line = line.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        for word in line.strip().split(' '):\n",
    "            document_vectors.at[word, current_doc] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       tsalta baptiste  karl richter (tennis)  matrix ab  sergey golubitskiy  \\\n",
       "                     4                      0          0                  16   \n",
       "0                    0                      0          0                   0   \n",
       "00                   0                      0          0                   0   \n",
       "000                  0                      0          0                   0   \n",
       "001                  0                      0          0                   0   \n",
       "...                ...                    ...        ...                 ...   \n",
       "ğ©¦ğ©§ğ©¢                  0                      0          0                   0   \n",
       "ğ©¦ğ©²ğ©§ğ©£                 0                      0          0                   0   \n",
       "ğ©±ğ©¡                   0                      0          0                   0   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                0                      0          0                   0   \n",
       "ğ©ºğ©¢ğ©³ğ©¨                 0                      0          0                   0   \n",
       "\n",
       "       west side story (earl hines album)  \\\n",
       "                                        0   \n",
       "0                                       0   \n",
       "00                                      0   \n",
       "000                                     0   \n",
       "001                                     0   \n",
       "...                                   ...   \n",
       "ğ©¦ğ©§ğ©¢                                     0   \n",
       "ğ©¦ğ©²ğ©§ğ©£                                    0   \n",
       "ğ©±ğ©¡                                      0   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                                   0   \n",
       "ğ©ºğ©¢ğ©³ğ©¨                                    0   \n",
       "\n",
       "       2016 tipperary senior hurling championship  mario mosbÃ¶ck  \\\n",
       "                                                0              0   \n",
       "0                                               0              0   \n",
       "00                                              0              0   \n",
       "000                                             0              0   \n",
       "001                                             0              0   \n",
       "...                                           ...            ...   \n",
       "ğ©¦ğ©§ğ©¢                                             0              0   \n",
       "ğ©¦ğ©²ğ©§ğ©£                                            0              0   \n",
       "ğ©±ğ©¡                                              0              0   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                                           0              0   \n",
       "ğ©ºğ©¢ğ©³ğ©¨                                            0              0   \n",
       "\n",
       "       faith baptist college  volodymyr dykyi  fÃ©lix baumaine  ...  \\\n",
       "                           0                0               3  ...   \n",
       "0                          0                0               0  ...   \n",
       "00                         0                0               0  ...   \n",
       "000                        0                0               0  ...   \n",
       "001                        0                0               0  ...   \n",
       "...                      ...              ...             ...  ...   \n",
       "ğ©¦ğ©§ğ©¢                        0                0               0  ...   \n",
       "ğ©¦ğ©²ğ©§ğ©£                       0                0               0  ...   \n",
       "ğ©±ğ©¡                         0                0               0  ...   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                      0                0               0  ...   \n",
       "ğ©ºğ©¢ğ©³ğ©¨                       0                0               0  ...   \n",
       "\n",
       "       pinkwash (band)  promo azteca  strange creek (west virginia)  \\\n",
       "                     0             0                              0   \n",
       "0                    0             0                              0   \n",
       "00                   0             0                              0   \n",
       "000                  0             0                              0   \n",
       "001                  0             0                              0   \n",
       "...                ...           ...                            ...   \n",
       "ğ©¦ğ©§ğ©¢                  0             0                              0   \n",
       "ğ©¦ğ©²ğ©§ğ©£                 0             0                              0   \n",
       "ğ©±ğ©¡                   0             0                              0   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                0             0                              0   \n",
       "ğ©ºğ©¢ğ©³ğ©¨                 0             0                              0   \n",
       "\n",
       "       strange creek  collective sigh  dileep agrawal  strouds creek  \\\n",
       "                   0                0               0              0   \n",
       "0                  0                0               0              0   \n",
       "00                 0                0               0              0   \n",
       "000                0                0               0              0   \n",
       "001                0                0               0              0   \n",
       "...              ...              ...             ...            ...   \n",
       "ğ©¦ğ©§ğ©¢                0                0               0              0   \n",
       "ğ©¦ğ©²ğ©§ğ©£               0                0               0              0   \n",
       "ğ©±ğ©¡                 0                0               0              0   \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£              0                0               0              0   \n",
       "ğ©ºğ©¢ğ©³ğ©¨               0                0               0              0   \n",
       "\n",
       "       mystic marathon  the daddy issues  vicky astori  \n",
       "                     1                 0             2  \n",
       "0                    0                 0             0  \n",
       "00                   0                 0             0  \n",
       "000                  0                 0             0  \n",
       "001                  0                 0             0  \n",
       "...                ...               ...           ...  \n",
       "ğ©¦ğ©§ğ©¢                  0                 0             0  \n",
       "ğ©¦ğ©²ğ©§ğ©£                 0                 0             0  \n",
       "ğ©±ğ©¡                   0                 0             0  \n",
       "ğ©±ğ©¥ğ©©ğ©§ğ©£                0                 0             0  \n",
       "ğ©ºğ©¢ğ©³ğ©¨                 0                 0             0  \n",
       "\n",
       "[75614 rows x 5784 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tsalta baptiste</th>\n      <th>karl richter (tennis)</th>\n      <th>matrix ab</th>\n      <th>sergey golubitskiy</th>\n      <th>west side story (earl hines album)</th>\n      <th>2016 tipperary senior hurling championship</th>\n      <th>mario mosbÃ¶ck</th>\n      <th>faith baptist college</th>\n      <th>volodymyr dykyi</th>\n      <th>fÃ©lix baumaine</th>\n      <th>...</th>\n      <th>pinkwash (band)</th>\n      <th>promo azteca</th>\n      <th>strange creek (west virginia)</th>\n      <th>strange creek</th>\n      <th>collective sigh</th>\n      <th>dileep agrawal</th>\n      <th>strouds creek</th>\n      <th>mystic marathon</th>\n      <th>the daddy issues</th>\n      <th>vicky astori</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>001</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ğ©¦ğ©§ğ©¢</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ğ©¦ğ©²ğ©§ğ©£</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ğ©±ğ©¡</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ğ©±ğ©¥ğ©©ğ©§ğ©£</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ğ©ºğ©¢ğ©³ğ©¨</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75614 rows Ã— 5784 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "document_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fair amount of these vocabulary words are numbers. We did not remove them since they might  be relevant to some queries. Eg. \"Football match in 2015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can notice already, most of these values are zero. This is because even if a term occurs only once in 5000 documents, it is assigned a term ID and a row is provided for it, creating 4999 empty cells. In this case, over 99% of the cells were empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of cells in the Inverted Index Matrix: 437351376\nNumber of cells which are empty: 436736378\nPercentage of empty cells: 99.8594 %\n"
     ]
    }
   ],
   "source": [
    "numberOfZeros = (document_vectors == 0).sum().sum()\n",
    "totalCells = document_vectors.shape[0]*document_vectors.shape[1]\n",
    "print(\"Number of cells in the Inverted Index Matrix:\", totalCells)\n",
    "print(\"Number of cells which are empty:\", numberOfZeros)\n",
    "print(\"Percentage of empty cells:\", round(numberOfZeros/totalCells * 100, 4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally, we write the `document_vectors` table to a file to be used to retrieve and rank user queries. This may take upto a few minutes, depending on the size of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current memory usage is 482.666055MB; Peak was 917.649134MB\n"
     ]
    }
   ],
   "source": [
    "document_vectors.to_csv('vector_space_model.csv')\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "source": [
    "In our testing, this index creation program had a peak memory usage of 917.64MB.\n",
    "Also the resulting csv File takes up 900MB of space "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0ddd3d7e86cbbc0e08bca60a5fc2395220a1f045b0d1d96eafb3eb8348c10d91f",
   "display_name": "Python 3.8.5  ('ir_env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ddd3d7e86cbbc0e08bca60a5fc2395220a1f045b0d1d96eafb3eb8348c10d91f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}