{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0ddd3d7e86cbbc0e08bca60a5fc2395220a1f045b0d1d96eafb3eb8348c10d91f",
   "display_name": "Python 3.8.5  ('ir_env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ddd3d7e86cbbc0e08bca60a5fc2395220a1f045b0d1d96eafb3eb8348c10d91f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Part 2 A.2: Inverted Index Optimization: Search\n",
    "\n",
    "We first import the required modules and the Inverted_Index class defined in the previous notebook\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import string\n",
    "import time\n",
    "from inverted_index import Inverted_Index\n",
    "\n"
   ]
  },
  {
   "source": [
    "For the search class, we use the Inverted_Index object created in the previous notebook. \n",
    "\n",
    "\n",
    "### Query Vector\n",
    "We take the input query and create a query vector using ltc scheme as described in part 1.\n",
    "\n",
    "### Document Vector\n",
    "For every term present in the query, we use the posting list corresponding to that term and update the values for the douments present in the posting list using the lnc scheme (described in part 1) in the document matrix.\n",
    "\n",
    "### Scores\n",
    "We simpy take the dot product of query vector with each row in the document matrix and update its score. The top K documents with the highest score are then returned \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "    \n",
    "    # k = number of results to be returned\n",
    "    def search(self, query, k = 10):\n",
    "        words = query.lower().strip().split()\n",
    "        terms = {}\n",
    "        for word in words :\n",
    "            if word not in index.InvertedIndex:\n",
    "                continue\n",
    "            terms[word] = words.count(word) \n",
    "        \n",
    "\n",
    "        #finding ltc for query\n",
    "        query_vector = np.add(np.log2(np.array(list(terms.values()), dtype=np.float64)),1)\n",
    "        query_vector = np.multiply(query_vector, np.log2((index.no_documents+1) /np.array(list(map(lambda x: self.index.InvertedIndex[x][1], terms.keys())))))\n",
    "        query_vector = query_vector/np.linalg.norm(query_vector)\n",
    "\n",
    "\n",
    "        docs_vector = pd.DataFrame(columns = list(terms.keys()), dtype = np.float64)\n",
    "        docs_encountered = dict()\n",
    "\n",
    "        # finding lnc for document\n",
    "        for word in list(terms.keys()):\n",
    "            postinglist , df = self.index.InvertedIndex[word]\n",
    "            head = postinglist.head\n",
    "\n",
    "            # if the word does not exist in document \n",
    "            if not head:\n",
    "                continue\n",
    "\n",
    "            # idf = math.log2((no_documents+1)/df)\n",
    "            idf = 1\n",
    "            while head:\n",
    "                # initializing the row if it does not exist \n",
    "                if not docs_encountered.get(head.docID):\n",
    "                    docs_vector.loc[head.docID] = 0\n",
    "                    docs_encountered[head.docID] = True\n",
    "                \n",
    "                #  df[docid][word] = tf*idf / Norm\n",
    "                docs_vector.loc[head.docID, word] = ((1 + math.log2(head.tf))) / self.index.magnitude[head.docID]\n",
    "                head = head.next\n",
    "        \n",
    "        \n",
    "        # calculating lnc.ltc\n",
    "        docs_vector['score$'] = docs_vector.dot(query_vector)\n",
    "\n",
    "        # returning the top K searches\n",
    "        docs_vector = docs_vector.sort_values(by='score$', ascending = False)\n",
    "        if k > docs_vector.shape[0]:\n",
    "            k = docs_vector.shape[0]\n",
    "            \n",
    "        results = docs_vector[['score$']].iloc[:k]\n",
    "        # formatting the results \n",
    "        results['Title'] = list(map(lambda x : self.index.docs[x], results.index))\n",
    "        results.reset_index(inplace = True)\n",
    "        results.drop('index', inplace=True, axis = 1)\n",
    "        return results[['Title', 'score$']]\n",
    "        "
   ]
  },
  {
   "source": [
    "Loading up the Inverted_Index object which was saved in Part 2 A.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"inverted_index_obj.pickle\", \"rb\")\n",
    "index = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "source": [
    "Creatng a object of the the Search class defined above and hence creating an IR system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = Search(index)"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Test Queries\n",
    "\n",
    "We have provided some sample queries to try out. Please uncomment the relevant line before running the query. There is also an option to enter your own query.\n",
    "\n",
    "Also, to measure the execution time of the program we initialize the starting time as start_time variable\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                     Title    score$\n0                 tax attractiveness index  0.146361\n1                                   axykno  0.107383\n2                clarehall shopping centre  0.090940\n3                       flow-through share  0.086226\n4              modified endowment contract  0.082823\n5                          thirtieth (tax)  0.077450\n6                             ottoman ayan  0.074638\n7                              allelengyon  0.068978\n8                        jorge roca suarez  0.053362\n9  m/s r.m.d.c (mysore) v. state of mysore  0.052988\n--- Time taken: 0.2368786334991455 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"tax planning strategies\"\n",
    "# query = \"north american beaver\"\n",
    "# query = \"car ride\"\n",
    "# query = \"falling off the edge of the world\"\n",
    "# query = \"guitar musician\"\n",
    "\n",
    "# query = input()\n",
    "\n",
    "results = system.search(query)\n",
    "print(results)\n",
    "\n",
    "print(\"--- Time taken: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "source": [
    "We find that the results are exactly the same as those found in Part A. This is because the optimization does not change the score or the ranking of any of the documents and simply affect the space used by the system.\n",
    "\n",
    "In our testing we got a running time of 0.66 seconds."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}